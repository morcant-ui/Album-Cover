{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Levenshtein in /home/christine/miniconda3/lib/python3.12/site-packages (0.26.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /home/christine/miniconda3/lib/python3.12/site-packages (from Levenshtein) (3.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import psutil\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from Levenshtein import distance\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET COMPUTER SPECS\n",
    "\n",
    "platform_info = {}\n",
    "\n",
    "platform_info['physical_cpu_cores'] = psutil.cpu_count(logical=False)\n",
    "platform_info['total_cpu_cores'] = psutil.cpu_count(logical=True)\n",
    "\n",
    "def get_available_device():\n",
    "    \"\"\"Helper method to find best possible hardware to run\n",
    "    Returns:\n",
    "        torch.device used to run experiments.\n",
    "        str representation of backend.\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\"), \"cuda\"\n",
    "\n",
    "    # Check if ROCm is available\n",
    "    if torch.version.hip is not None and torch.backends.mps.is_available():\n",
    "        return torch.device(\"rocm\"), \"rocm\"\n",
    "\n",
    "    # Check if MPS (Apple Silicon) is available\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('cpu'), \"mps\"\n",
    "\n",
    "    # Fall back to CPU\n",
    "    return torch.device(\"cpu\"), \"cpu\"\n",
    "\n",
    "# Check device info\n",
    "device, backend = get_available_device()\n",
    "\n",
    "# Check for GPU-specific details if CUDA or ROCm is available\n",
    "if device.type == \"cuda\":\n",
    "    cuda_device_count = torch.cuda.device_count()\n",
    "    cuda_device_name = torch.cuda.get_device_name(0)\n",
    "    cuda_version = torch.version.cuda\n",
    "elif device.type == \"rocm\":\n",
    "    cuda_device_count = torch.cuda.device_count()\n",
    "    cuda_device_name = torch.cuda.get_device_name(0)\n",
    "    cuda_version = torch.version.hip\n",
    "else:\n",
    "    cuda_device_count = 0\n",
    "    cuda_device_name = \"N/A\"\n",
    "    cuda_version = \"N/A\"\n",
    "\n",
    "platform_info['device'] = device.type\n",
    "platform_info['backend'] = backend\n",
    "platform_info['cuda_device_count'] = cuda_device_count\n",
    "platform_info['cuda_device_name'] = cuda_device_name\n",
    "platform_info['cuda_version'] = cuda_version\n",
    "\n",
    "# print(json.dumps(platform_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIVE PROMPT TEMPLATES\n",
    "\n",
    "SIMILARITY_DISTANCE = 3\n",
    "def are_tracks_similar(tracks):\n",
    "    for i in range(len(tracks)):\n",
    "        for j in range(i + 1, len(tracks)):\n",
    "            if distance(tracks[i]['name'], tracks[j]['name']) < SIMILARITY_DISTANCE:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def similarity_groups(tracks):\n",
    "    found_group = [False] * len(tracks)\n",
    "    groups = []\n",
    "\n",
    "    for i in range(len(tracks)):\n",
    "        if found_group[i]:\n",
    "            continue\n",
    "\n",
    "        found_group[i] = True\n",
    "        groups.append([tracks[i]])\n",
    "\n",
    "        for j in range(i + 1, len(tracks)):\n",
    "            if found_group[j]:\n",
    "                continue\n",
    "            if distance(tracks[i]['name'], tracks[j]['name']) < SIMILARITY_DISTANCE:\n",
    "                found_group[j] = True\n",
    "\n",
    "    return groups\n",
    "\n",
    "pos_prompt_templates = {}\n",
    "\n",
    "pos_prompt_templates['1-long'] =  Template(\"\"\"\\\n",
    "Album cover for this album:\n",
    "Album name : {{ album.name }}\n",
    "Artist{% if album.artists|length > 1 %}s{% endif %} : {{ album.artists | join(', ') }}\n",
    "Release Date : {{ album.date }}\n",
    "Label : {{ album.label }}\n",
    "Tracks:\n",
    "{% for track in album.tracks %}- {{ track.name }}\\n{% endfor %}\n",
    "\"\"\")\n",
    "\n",
    "pos_prompt_templates['2-only-tracks'] =  Template(\"\"\"\\\n",
    "Album cover for these tracks: \n",
    "{% for track in album.tracks %}- {{ track.name }}\\n{% endfor %}\n",
    "\"\"\")\n",
    "\n",
    "pos_prompt_templates['3-only-title'] =  Template(\"\"\"\\\n",
    "Album cover for \"{{ album.name }}\"\n",
    "\"\"\")\n",
    "\n",
    "pos_prompt_templates['4-long-with-track-similarity'] =  Template(\"\"\"\\\n",
    "Album cover for this album:\n",
    "Album name : {{ album.name }}\n",
    "Artist{% if album.artists|length > 1 %}s{% endif %} : {{ album.artists | join(', ') }}\n",
    "Release Date : {{ album.date }}\n",
    "Label : {{ album.label }}\n",
    "\n",
    "{% if are_tracks_similar(album.tracks) %} Track format : {% for track in similarity_groups(album.tracks) %}- {{ track.name }}\\n{% endfor %}\n",
    "{% else %} Tracks:\n",
    "{% for track in album.tracks %}- {{ track.name }}\\n{% endfor %}{% endif %}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEGATIVE PROMPT TEMPLATES\n",
    "\n",
    "neg_prompts = {}\n",
    "neg_prompts['1-no-text'] = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALBUM DATA\n",
    "\n",
    "file_id = \"\" # if need for a specific album, put the file name here\n",
    "\n",
    "if file_id == \"\":\n",
    "    album_files = os.listdir('input/albums')\n",
    "    random_album_file = random.choice(album_files)\n",
    "else:\n",
    "    random_album_file = f'{file_id}.json'\n",
    "\n",
    "with open(f'input/albums/{random_album_file}', 'r') as file:\n",
    "    album_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHER PARAMETERS\n",
    "\n",
    "INFERENCE_STEPS = [20, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"computer_specs\": {\n",
      "        \"physical_cpu_cores\": 4,\n",
      "        \"total_cpu_cores\": 8,\n",
      "        \"device\": \"cpu\",\n",
      "        \"backend\": \"cpu\",\n",
      "        \"cuda_device_count\": 0,\n",
      "        \"cuda_device_name\": \"N/A\",\n",
      "        \"cuda_version\": \"N/A\"\n",
      "    },\n",
      "    \"album_id\": \"0OYCfnuIteT2ECqMW8XtwY\",\n",
      "    \"pos_prompt\": \"1-long\",\n",
      "    \"neg_prompt\": \"1-no-text\",\n",
      "    \"inference_steps\": 100\n",
      "}\n",
      "{\n",
      "    \"computer_specs\": {\n",
      "        \"physical_cpu_cores\": 4,\n",
      "        \"total_cpu_cores\": 8,\n",
      "        \"device\": \"cpu\",\n",
      "        \"backend\": \"cpu\",\n",
      "        \"cuda_device_count\": 0,\n",
      "        \"cuda_device_name\": \"N/A\",\n",
      "        \"cuda_version\": \"N/A\"\n",
      "    },\n",
      "    \"album_id\": \"0OYCfnuIteT2ECqMW8XtwY\",\n",
      "    \"pos_prompt\": \"2-only-tracks\",\n",
      "    \"neg_prompt\": \"1-no-text\",\n",
      "    \"inference_steps\": 100\n",
      "}\n",
      "{\n",
      "    \"computer_specs\": {\n",
      "        \"physical_cpu_cores\": 4,\n",
      "        \"total_cpu_cores\": 8,\n",
      "        \"device\": \"cpu\",\n",
      "        \"backend\": \"cpu\",\n",
      "        \"cuda_device_count\": 0,\n",
      "        \"cuda_device_name\": \"N/A\",\n",
      "        \"cuda_version\": \"N/A\"\n",
      "    },\n",
      "    \"album_id\": \"0OYCfnuIteT2ECqMW8XtwY\",\n",
      "    \"pos_prompt\": \"3-only-title\",\n",
      "    \"neg_prompt\": \"1-no-text\",\n",
      "    \"inference_steps\": 100\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# CREATE RUN PARAMETERS\n",
    "\n",
    "run_info = {}\n",
    "run_info['computer_specs'] = platform_info\n",
    "run_info['album_id'] = album_data['id']\n",
    "\n",
    "is_similar = are_tracks_similar(album_data['tracks'])\n",
    "\n",
    "torch.cuda.empty_cache() # not sure if this is necessary\n",
    "\n",
    "for pos_key, template in pos_prompt_templates.items():\n",
    "\n",
    "    # Skip prompt if the tracks are not similar\n",
    "    if pos_key == '4-long-with-track-similarity' and not is_similar:\n",
    "        continue\n",
    "\n",
    "    curr_run_info = run_info.copy()\n",
    "    curr_run_info['pos_prompt'] = pos_key\n",
    "\n",
    "    for neg_key, neg_prompt in neg_prompts.items():\n",
    "        curr_run_info['neg_prompt'] = neg_key\n",
    "\n",
    "        for step in INFERENCE_STEPS:\n",
    "            curr_run_info['inference_steps'] = step\n",
    "\n",
    "    print(json.dumps(curr_run_info, indent=4))\n",
    "\n",
    "    del curr_run_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
